# Nova Rule: The Prompt Pattern Matching

## Description
With the widespread adoption of LLMs and Generative AI, individuals and organizations are leveraging these technologies daily, whether for customer support automation, code generation, or business automation. But with increased adoption comes new security risks. The attack surface is expanding, and security teams still lack clear strategies for detecting malicious GenAI activity.

How do you identify threat actor activity in your AI system?

How do you detect malicious prompt usage?

How can threat intelligence teams hunt for adversarial GenAI behavior?

That's where NOVA comes in.

NOVA is an early-stage tool for prompt hunting, designed to detect malicious or policy-violating prompts within GenAI systems. If your organization runs an AI-powered service, you might need a way to monitor, analyze, and detect specific prompt patterns before they lead to abuse, data leaks, or security incidents.

## Code
https://github.com/fr0gger/nova-framework
